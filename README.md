# Application RAG avec LangChain et Qdrant

## ğŸš€ Description

Application RAG (Retrieval-Augmented Generation) complÃ¨te et modulaire utilisant LangChain et Qdrant pour la recherche sÃ©mantique et la gÃ©nÃ©ration de rÃ©ponses basÃ©es sur des documents.

## âœ¨ FonctionnalitÃ©s

### FonctionnalitÃ©s de Base
- **Chargement de documents web** avec BeautifulSoup
- **DÃ©coupage intelligent** en chunks avec chevauchement
- **GÃ©nÃ©ration d'embeddings** avec OpenAI text-embedding-3-small
- **Stockage vectoriel** dans Qdrant
- **Recherche sÃ©mantique** par similaritÃ© cosinus
- **GÃ©nÃ©ration de rÃ©ponses** avec GPT-4o-mini
- **Architecture modulaire** et extensible

### ğŸš€ NouveautÃ©s : Modes RAG AvancÃ©s
- **4 stratÃ©gies RAG** : Naive, Hybrid, Corrective, Self-Reflective
- **Changement dynamique** de mode selon vos besoins
- **Comparaison automatique** entre stratÃ©gies
- **MÃ©triques de performance** dÃ©taillÃ©es
- **Tests et benchmarks** intÃ©grÃ©s
- **Interface unifiÃ©e** pour tous les modes

## ğŸ› ï¸ Technologies

- **LangChain** : Framework pour applications LLM
- **OpenAI** : ModÃ¨les GPT-4o-mini et text-embedding-3-small
- **Qdrant** : Base de donnÃ©es vectorielle
- **BeautifulSoup** : Parsing HTML
- **Python 3.10+** : Langage principal

## ğŸ“‹ PrÃ©requis

- Python 3.10 ou supÃ©rieur
- ClÃ© API OpenAI
- Environnement virtuel Python

## ğŸ”§ Installation

1. **Cloner le dÃ©pÃ´t**
   ```bash
   git clone <url-du-depot>
   cd RAG-langchain-Exampke
   ```

2. **CrÃ©er l'environnement virtuel**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Linux/Mac
   # ou
   .venv\Scripts\activate     # Windows
   ```

3. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```
   
   Ou installation manuelle :
   ```bash
   pip install -qU "langchain[openai]"
   pip install -qU langchain-qdrant
   pip install python-dotenv
   pip install beautifulsoup4
   pip install langchain-community
   
   # Pour les modes RAG avancÃ©s
   pip install rank-bm25 sentence-transformers duckduckgo-search
   ```

4. **Configurer les variables d'environnement**
   
   CrÃ©er un fichier `.env` Ã  la racine du projet :
   ```env
   OPENAI_API_KEY=sk-votre-cle-api-openai
   ```

## ğŸš€ Utilisation

### ExÃ©cution simple (mode original)

```bash
python main.py
```

### ğŸ¯ Modes RAG AvancÃ©s

```bash
# Test interactif des modes
python test_rag_modes.py --interactive

# Comparaison automatique
python test_rag_modes.py

# Benchmark complet
python test_rag_modes.py --benchmark
```

### Utilisation programmatique

#### Mode Original
```python
from main import RAGApplication

app = RAGApplication()
app.setup_environment()
app.initialize_models()
app.setup_vector_store()

documents = app.load_and_process_documents("https://example.com/article")
app.populate_vector_store(documents)

response, sources = app.ask_question("Quelle est la question ?")
print(response)
```

#### Modes AvancÃ©s
```python
from enhanced_rag_app import EnhancedRAGApplication

# Initialisation avec mode par dÃ©faut
app = EnhancedRAGApplication(default_strategy='hybrid')
app.setup_environment()
app.initialize_models()
app.setup_vector_store()
app.initialize_strategies()

# Chargement documents
documents = app.load_and_process_documents("https://example.com/article")
app.populate_vector_store(documents)

# Changement de mode et utilisation
app.set_strategy('corrective')  # ou 'hybrid', 'reflective', 'naive'
result = app.ask_question("Votre question")

# Comparaison entre modes
comparison = app.compare_strategies("Votre question")
print(f"Meilleure stratÃ©gie: {comparison.best_strategy}")
```

### ğŸ“– Guide DÃ©taillÃ©

Pour une documentation complÃ¨te de l'architecture et des modes avancÃ©s, consultez :
- **[QUICK_START_GUIDE.md](QUICK_START_GUIDE.md)** - Guide complet avec architecture
- **[RAG_MODES_ANALYSIS.md](RAG_MODES_ANALYSIS.md)** - Analyse dÃ©taillÃ©e des modes

## ğŸ“ Structure du projet

```
RAG-langchain-Exampke/
â”œâ”€â”€ main.py                    # ğŸ  Application RAG originale (mode Naive)
â”œâ”€â”€ rag_strategies.py          # ğŸ§  StratÃ©gies RAG (Pattern Strategy)
â”œâ”€â”€ enhanced_rag_app.py        # ğŸš€ Application amÃ©liorÃ©e (tous modes)
â”œâ”€â”€ test_rag_modes.py          # ğŸ§ª Tests et comparaisons des modes
â”œâ”€â”€ display_documents.py       # ğŸ‘ï¸ Affichage des documents
â”œâ”€â”€ load_documents.py          # ğŸ“¥ Chargement de documents
â”œâ”€â”€ example_usage.py           # ğŸ“š Exemples d'utilisation
â”œâ”€â”€ RAG_MODES_ANALYSIS.md      # ğŸ“Š Analyse dÃ©taillÃ©e des modes
â”œâ”€â”€ QUICK_START_GUIDE.md       # ğŸš€ Guide complet avec architecture
â”œâ”€â”€ .env                       # Variables d'environnement (non versionnÃ©)
â”œâ”€â”€ .gitignore                # Fichiers ignorÃ©s par Git
â”œâ”€â”€ README.md                 # Documentation du projet
â””â”€â”€ requirements.txt          # DÃ©pendances Python (base + avancÃ©es)
```

### Fichiers Principaux

- **`main.py`** : Application RAG de base (compatible avec votre code existant)
- **`enhanced_rag_app.py`** : Version avancÃ©e avec support multi-modes
- **`rag_strategies.py`** : ImplÃ©mentation des 4 stratÃ©gies RAG
- **`test_rag_modes.py`** : Scripts de test et benchmark

## ğŸ”’ SÃ©curitÃ©

- Le fichier `.env` est ignorÃ© par Git pour protÃ©ger les clÃ©s API
- Les clÃ©s API ne sont jamais affichÃ©es dans les logs
- Utilisation d'environnements virtuels pour l'isolation

## ğŸ§ª Tests

L'application inclut une dÃ©monstration complÃ¨te qui teste :

1. **Chargement de documents** depuis une URL
2. **DÃ©coupage en chunks** (63 chunks pour 43k caractÃ¨res)
3. **Stockage vectoriel** dans Qdrant
4. **Recherche sÃ©mantique** avec diffÃ©rentes questions
5. **GÃ©nÃ©ration de rÃ©ponses** basÃ©es sur le contexte

## ğŸ“Š Performance

- **Embeddings** : text-embedding-3-small (1536 dimensions)
- **LLM** : GPT-4o-mini avec tempÃ©rature 0.1
- **Base vectorielle** : Qdrant avec distance COSINE
- **Chunks** : 1000 caractÃ¨res avec chevauchement de 200

## ğŸ”§ Configuration avancÃ©e

### Modifier les paramÃ¨tres de dÃ©coupage

```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # Taille des chunks
    chunk_overlap=200,     # Chevauchement
    add_start_index=True,  # Suivi de position
)
```

### Changer le modÃ¨le d'embedding

```python
self.embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
```

### Utiliser Qdrant en production

```python
self.client = QdrantClient("localhost", port=6333)
```

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ†˜ Support

Pour toute question ou problÃ¨me :

1. VÃ©rifier la documentation
2. Consulter les issues existantes
3. CrÃ©er une nouvelle issue avec les dÃ©tails du problÃ¨me

## ğŸ”„ Mise Ã  jour

Pour mettre Ã  jour les dÃ©pendances :

```bash
pip install --upgrade langchain langchain-openai langchain-qdrant
```

---

**Note** : Ce projet est configurÃ© pour Ãªtre privÃ© par dÃ©faut. Assurez-vous de configurer la visibilitÃ© appropriÃ©e sur votre plateforme Git. 