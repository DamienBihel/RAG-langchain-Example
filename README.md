# Application RAG avec LangChain et Qdrant

## ğŸš€ Description

Application RAG (Retrieval-Augmented Generation) complÃ¨te et modulaire utilisant LangChain et Qdrant pour la recherche sÃ©mantique et la gÃ©nÃ©ration de rÃ©ponses basÃ©es sur des documents.

## âœ¨ FonctionnalitÃ©s

- **Chargement de documents web** avec BeautifulSoup
- **DÃ©coupage intelligent** en chunks avec chevauchement
- **GÃ©nÃ©ration d'embeddings** avec OpenAI text-embedding-3-small
- **Stockage vectoriel** dans Qdrant
- **Recherche sÃ©mantique** par similaritÃ© cosinus
- **GÃ©nÃ©ration de rÃ©ponses** avec GPT-4o-mini
- **Architecture modulaire** et extensible

## ğŸ› ï¸ Technologies

- **LangChain** : Framework pour applications LLM
- **OpenAI** : ModÃ¨les GPT-4o-mini et text-embedding-3-small
- **Qdrant** : Base de donnÃ©es vectorielle
- **BeautifulSoup** : Parsing HTML
- **Python 3.10+** : Langage principal

## ğŸ“‹ PrÃ©requis

- Python 3.10 ou supÃ©rieur
- ClÃ© API OpenAI
- Environnement virtuel Python

## ğŸ”§ Installation

1. **Cloner le dÃ©pÃ´t**
   ```bash
   git clone <url-du-depot>
   cd RAG-langchain-Exampke
   ```

2. **CrÃ©er l'environnement virtuel**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Linux/Mac
   # ou
   .venv\Scripts\activate     # Windows
   ```

3. **Installer les dÃ©pendances**
   ```bash
   pip install -qU "langchain[openai]"
   pip install -qU langchain-qdrant
   pip install python-dotenv
   pip install beautifulsoup4
   pip install langchain-community
   ```

4. **Configurer les variables d'environnement**
   
   CrÃ©er un fichier `.env` Ã  la racine du projet :
   ```env
   OPENAI_API_KEY=sk-votre-cle-api-openai
   ```

## ğŸš€ Utilisation

### ExÃ©cution simple

```bash
python main.py
```

### Utilisation programmatique

```python
from main import RAGApplication

# CrÃ©er l'application
app = RAGApplication()

# Configuration
app.setup_environment()
app.initialize_models()
app.setup_vector_store()

# Charger des documents
documents = app.load_and_process_documents("https://example.com/article")
app.populate_vector_store(documents)

# Poser une question
response, sources = app.ask_question("Quelle est la question ?")
print(response)
```

## ğŸ“ Structure du projet

```
RAG-langchain-Exampke/
â”œâ”€â”€ main.py              # Application RAG principale
â”œâ”€â”€ .env                 # Variables d'environnement (non versionnÃ©)
â”œâ”€â”€ .gitignore          # Fichiers ignorÃ©s par Git
â”œâ”€â”€ README.md           # Documentation du projet
â””â”€â”€ requirements.txt    # DÃ©pendances Python
```

## ğŸ”’ SÃ©curitÃ©

- Le fichier `.env` est ignorÃ© par Git pour protÃ©ger les clÃ©s API
- Les clÃ©s API ne sont jamais affichÃ©es dans les logs
- Utilisation d'environnements virtuels pour l'isolation

## ğŸ§ª Tests

L'application inclut une dÃ©monstration complÃ¨te qui teste :

1. **Chargement de documents** depuis une URL
2. **DÃ©coupage en chunks** (63 chunks pour 43k caractÃ¨res)
3. **Stockage vectoriel** dans Qdrant
4. **Recherche sÃ©mantique** avec diffÃ©rentes questions
5. **GÃ©nÃ©ration de rÃ©ponses** basÃ©es sur le contexte

## ğŸ“Š Performance

- **Embeddings** : text-embedding-3-small (1536 dimensions)
- **LLM** : GPT-4o-mini avec tempÃ©rature 0.1
- **Base vectorielle** : Qdrant avec distance COSINE
- **Chunks** : 1000 caractÃ¨res avec chevauchement de 200

## ğŸ”§ Configuration avancÃ©e

### Modifier les paramÃ¨tres de dÃ©coupage

```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # Taille des chunks
    chunk_overlap=200,     # Chevauchement
    add_start_index=True,  # Suivi de position
)
```

### Changer le modÃ¨le d'embedding

```python
self.embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
```

### Utiliser Qdrant en production

```python
self.client = QdrantClient("localhost", port=6333)
```

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ†˜ Support

Pour toute question ou problÃ¨me :

1. VÃ©rifier la documentation
2. Consulter les issues existantes
3. CrÃ©er une nouvelle issue avec les dÃ©tails du problÃ¨me

## ğŸ”„ Mise Ã  jour

Pour mettre Ã  jour les dÃ©pendances :

```bash
pip install --upgrade langchain langchain-openai langchain-qdrant
```

---

**Note** : Ce projet est configurÃ© pour Ãªtre privÃ© par dÃ©faut. Assurez-vous de configurer la visibilitÃ© appropriÃ©e sur votre plateforme Git. 