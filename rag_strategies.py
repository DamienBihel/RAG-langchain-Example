"""
Strat√©gies RAG Avanc√©es - Architecture Modulaire

Ce module impl√©mente diff√©rentes strat√©gies RAG utilisant le pattern Strategy
pour permettre le changement dynamique de mode selon les besoins.

Strat√©gies disponibles :
1. NaiveRAG - Impl√©mentation basique (actuelle)
2. HybridSearchRAG - Combine BM25 + recherche vectorielle
3. CorrectiveRAG - √âvalue et corrige les documents r√©cup√©r√©s
4. SelfReflectiveRAG - Auto-√©value et raffine les r√©ponses
5. AgentBasedRAG - Routage intelligent des requ√™tes
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional, Tuple
import time
from dataclasses import dataclass

from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import OpenAIEmbeddings
from langchain.chat_models import init_chat_model


@dataclass
class RAGResult:
    """R√©sultat d'une op√©ration RAG avec m√©tadonn√©es d√©taill√©es."""
    response: str
    sources: List[Document]
    metadata: Dict[str, Any]
    processing_time: float
    confidence_score: float = 0.0
    strategy_used: str = ""


class RAGStrategy(ABC):
    """
    Classe abstraite d√©finissant l'interface pour les strat√©gies RAG.
    
    Utilise le pattern Strategy pour permettre le changement dynamique
    de comportement selon les besoins sp√©cifiques.
    """
    
    def __init__(self, llm=None, embeddings=None, vector_store=None):
        """
        Initialise la strat√©gie RAG avec les composants n√©cessaires.
        
        Args:
            llm: Mod√®le de langage pour la g√©n√©ration
            embeddings: Mod√®le d'embeddings pour la vectorisation
            vector_store: Base vectorielle pour le stockage
        """
        self.llm = llm
        self.embeddings = embeddings
        self.vector_store = vector_store
        self.name = self.__class__.__name__
    
    @abstractmethod
    def retrieve(self, query: str, k: int = 5) -> List[Document]:
        """
        R√©cup√®re les documents pertinents pour une requ√™te.
        
        Args:
            query: Requ√™te utilisateur
            k: Nombre de documents √† r√©cup√©rer
            
        Returns:
            Liste des documents pertinents
        """
        pass
    
    @abstractmethod
    def generate(self, query: str, documents: List[Document]) -> str:
        """
        G√©n√®re une r√©ponse bas√©e sur les documents r√©cup√©r√©s.
        
        Args:
            query: Requ√™te utilisateur
            documents: Documents de contexte
            
        Returns:
            R√©ponse g√©n√©r√©e
        """
        pass
    
    def retrieve_and_generate(self, query: str, k: int = 5) -> RAGResult:
        """
        Pipeline RAG complet : r√©cup√©ration + g√©n√©ration.
        
        Args:
            query: Requ√™te utilisateur
            k: Nombre de documents √† r√©cup√©rer
            
        Returns:
            RAGResult avec r√©ponse et m√©tadonn√©es
        """
        start_time = time.time()
        
        # R√©cup√©ration des documents
        documents = self.retrieve(query, k)
        
        # G√©n√©ration de la r√©ponse
        response = self.generate(query, documents)
        
        # Calcul des m√©tadonn√©es
        processing_time = time.time() - start_time
        metadata = {
            "query": query,
            "documents_count": len(documents),
            "strategy": self.name,
            "retrieval_time": processing_time
        }
        
        return RAGResult(
            response=response,
            sources=documents,
            metadata=metadata,
            processing_time=processing_time,
            strategy_used=self.name
        )
    
    def evaluate_documents(self, query: str, documents: List[Document]) -> List[float]:
        """
        √âvalue la pertinence des documents pour une requ√™te.
        
        Args:
            query: Requ√™te utilisateur
            documents: Documents √† √©valuer
            
        Returns:
            Liste des scores de pertinence (0-1)
        """
        # Impl√©mentation basique - peut √™tre overrid√©e
        return [1.0] * len(documents)


class NaiveRAG(RAGStrategy):
    """
    Strat√©gie RAG basique - Impl√©mentation actuelle.
    
    Utilise uniquement la recherche vectorielle par similarit√© cosinus
    sans validation ni optimisation suppl√©mentaire.
    """
    
    def retrieve(self, query: str, k: int = 5) -> List[Document]:
        """Recherche vectorielle basique."""
        if not self.vector_store:
            raise ValueError("Vector store not configured")
        
        return self.vector_store.similarity_search(query, k=k)
    
    def generate(self, query: str, documents: List[Document]) -> str:
        """G√©n√©ration basique avec template simple."""
        if not self.llm:
            raise ValueError("LLM not configured")
        
        # Pr√©paration du contexte
        context = "\n\n".join([doc.page_content for doc in documents])
        
        # Template de prompt basique
        prompt = ChatPromptTemplate.from_template("""
Vous √™tes un assistant IA. R√©pondez √† la question en vous basant sur le contexte fourni.

Contexte:
{context}

Question: {question}

R√©ponse:""")
        
        # G√©n√©ration
        messages = prompt.format_messages(context=context, question=query)
        response = self.llm.invoke(messages)
        
        return response.content


class HybridSearchRAG(RAGStrategy):
    """
    Strat√©gie RAG hybride combinant recherche vectorielle et BM25.
    
    Utilise un EnsembleRetriever pour combiner :
    - Recherche s√©mantique (embeddings)
    - Recherche lexicale (BM25)
    """
    
    def __init__(self, llm=None, embeddings=None, vector_store=None, 
                 vector_weight: float = 0.7, bm25_weight: float = 0.3):
        """
        Initialise la strat√©gie hybride.
        
        Args:
            vector_weight: Poids pour la recherche vectorielle
            bm25_weight: Poids pour la recherche BM25
        """
        super().__init__(llm, embeddings, vector_store)
        self.vector_weight = vector_weight
        self.bm25_weight = bm25_weight
        self.bm25_retriever = None
        self.ensemble_retriever = None
    
    def setup_bm25_retriever(self, documents: List[Document]):
        """
        Configure le retrieveur BM25 avec les documents.
        
        Args:
            documents: Corpus de documents pour BM25
        """
        try:
            from langchain_community.retrievers import BM25Retriever
            from langchain.retrievers import EnsembleRetriever
            
            # Configuration BM25
            self.bm25_retriever = BM25Retriever.from_documents(documents)
            self.bm25_retriever.k = 5
            
            # Configuration ensemble
            if self.vector_store:
                vector_retriever = self.vector_store.as_retriever(search_kwargs={"k": 5})
                
                self.ensemble_retriever = EnsembleRetriever(
                    retrievers=[vector_retriever, self.bm25_retriever],
                    weights=[self.vector_weight, self.bm25_weight]
                )
                
                print(f"‚úÖ Hybrid Search configur√© (Vector: {self.vector_weight}, BM25: {self.bm25_weight})")
            
        except ImportError:
            print("‚ùå BM25Retriever non disponible. Utilisez: pip install rank-bm25")
            raise
    
    def retrieve(self, query: str, k: int = 5) -> List[Document]:
        """Recherche hybride BM25 + vectorielle."""
        if not self.ensemble_retriever:
            # Fallback sur recherche vectorielle
            print("‚ö†Ô∏è  Ensemble retriever non configur√©, utilisation vectorielle seule")
            return self.vector_store.similarity_search(query, k=k)
        
        # Recherche hybride
        results = self.ensemble_retriever.get_relevant_documents(query)
        return results[:k]
    
    def generate(self, query: str, documents: List[Document]) -> str:
        """G√©n√©ration optimis√©e avec template am√©lior√©."""
        if not self.llm:
            raise ValueError("LLM not configured")
        
        # Pr√©paration du contexte avec scores
        context_parts = []
        for i, doc in enumerate(documents):
            source_info = doc.metadata.get('source', 'Unknown')
            context_parts.append(f"Document {i+1} (Source: {source_info}):\n{doc.page_content}")
        
        context = "\n\n".join(context_parts)
        
        # Template am√©lior√©
        prompt = ChatPromptTemplate.from_template("""
Vous √™tes un assistant IA expert. Analysez les documents fournis et r√©pondez √† la question.

INSTRUCTIONS:
- Basez-vous uniquement sur les documents fournis
- Citez les sources quand c'est pertinent
- Si l'information n'est pas dans les documents, indiquez-le clairement

DOCUMENTS:
{context}

QUESTION: {question}

R√âPONSE:""")
        
        messages = prompt.format_messages(context=context, question=query)
        response = self.llm.invoke(messages)
        
        return response.content


class CorrectiveRAG(RAGStrategy):
    """
    Strat√©gie RAG corrective qui √©value et corrige les documents r√©cup√©r√©s.
    
    Processus :
    1. R√©cup√©ration initiale des documents
    2. √âvaluation de la pertinence
    3. Correction si n√©cessaire (recherche web, etc.)
    4. G√©n√©ration avec documents corrig√©s
    """
    
    def __init__(self, llm=None, embeddings=None, vector_store=None,
                 relevance_threshold: float = 0.5, max_corrections: int = 2):
        """
        Initialise la strat√©gie corrective.
        
        Args:
            relevance_threshold: Seuil de pertinence pour correction
            max_corrections: Nombre maximum de corrections
        """
        super().__init__(llm, embeddings, vector_store)
        self.relevance_threshold = relevance_threshold
        self.max_corrections = max_corrections
        self.evaluator = None
    
    def setup_evaluator(self):
        """Configure l'√©valuateur de pertinence."""
        try:
            from sentence_transformers import CrossEncoder
            
            # Mod√®le d'√©valuation cross-encoder
            self.evaluator = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')
            print("‚úÖ √âvaluateur de pertinence configur√©")
            
        except ImportError:
            print("‚ùå CrossEncoder non disponible. Utilisez: pip install sentence-transformers")
            self.evaluator = None
    
    def evaluate_documents(self, query: str, documents: List[Document]) -> List[float]:
        """
        √âvalue la pertinence des documents avec un mod√®le sp√©cialis√©.
        
        Args:
            query: Requ√™te utilisateur
            documents: Documents √† √©valuer
            
        Returns:
            Liste des scores de pertinence (0-1)
        """
        if not self.evaluator:
            # Fallback sur √©valuation basique
            return [1.0] * len(documents)
        
        # √âvaluation avec cross-encoder
        pairs = [(query, doc.page_content[:512]) for doc in documents]  # Limite √† 512 chars
        scores = self.evaluator.predict(pairs)
        
        # Normalisation des scores (0-1)
        normalized_scores = [(score + 1) / 2 for score in scores]
        
        return normalized_scores
    
    def retrieve(self, query: str, k: int = 5) -> List[Document]:
        """R√©cup√©ration avec √©valuation et correction."""
        if not self.vector_store:
            raise ValueError("Vector store not configured")
        
        # R√©cup√©ration initiale
        documents = self.vector_store.similarity_search(query, k=k*2)  # Plus de documents
        
        # √âvaluation des documents
        scores = self.evaluate_documents(query, documents)
        
        # Filtrage par pertinence
        relevant_docs = []
        for doc, score in zip(documents, scores):
            doc.metadata['relevance_score'] = score
            if score >= self.relevance_threshold:
                relevant_docs.append(doc)
        
        # Correction si pas assez de documents pertinents
        if len(relevant_docs) < k // 2:
            print(f"‚ö†Ô∏è  Seulement {len(relevant_docs)} documents pertinents trouv√©s")
            print("üîÑ Tentative de correction avec recherche web...")
            
            # Recherche web de secours
            web_docs = self.web_search_fallback(query, k - len(relevant_docs))
            relevant_docs.extend(web_docs)
        
        return relevant_docs[:k]
    
    def web_search_fallback(self, query: str, k: int) -> List[Document]:
        """
        Recherche web de secours quand les documents locaux sont insuffisants.
        
        Args:
            query: Requ√™te de recherche
            k: Nombre de r√©sultats souhait√©s
            
        Returns:
            Liste de documents depuis la recherche web
        """
        try:
            from duckduckgo_search import DDGS
            
            # Recherche DuckDuckGo
            with DDGS() as ddgs:
                results = list(ddgs.text(query, max_results=k))
            
            # Conversion en documents
            web_docs = []
            for result in results:
                doc = Document(
                    page_content=result.get('body', ''),
                    metadata={
                        'source': result.get('href', ''),
                        'title': result.get('title', ''),
                        'type': 'web_search',
                        'relevance_score': 0.8  # Score par d√©faut pour recherche web
                    }
                )
                web_docs.append(doc)
            
            print(f"‚úÖ {len(web_docs)} documents r√©cup√©r√©s via recherche web")
            return web_docs
            
        except ImportError:
            print("‚ùå DuckDuckGo search non disponible. Utilisez: pip install duckduckgo-search")
            return []
        except Exception as e:
            print(f"‚ùå Erreur recherche web: {e}")
            return []
    
    def generate(self, query: str, documents: List[Document]) -> str:
        """G√©n√©ration avec prise en compte des scores de pertinence."""
        if not self.llm:
            raise ValueError("LLM not configured")
        
        # Tri des documents par pertinence
        documents_sorted = sorted(documents, 
                                key=lambda d: d.metadata.get('relevance_score', 0), 
                                reverse=True)
        
        # Pr√©paration du contexte avec scores
        context_parts = []
        for i, doc in enumerate(documents_sorted):
            score = doc.metadata.get('relevance_score', 0)
            source = doc.metadata.get('source', 'Unknown')
            doc_type = doc.metadata.get('type', 'local')
            
            context_parts.append(
                f"Document {i+1} [Pertinence: {score:.2f}] [Type: {doc_type}] [Source: {source}]:\n"
                f"{doc.page_content[:800]}..."
            )
        
        context = "\n\n".join(context_parts)
        
        # Template avec gestion de la pertinence
        prompt = ChatPromptTemplate.from_template("""
Vous √™tes un assistant IA expert en analyse de documents. 

INSTRUCTIONS:
- Analysez les documents fournis (tri√©s par pertinence)
- Privil√©giez les documents avec un score de pertinence √©lev√©
- Indiquez si certaines informations proviennent de sources externes
- Soyez transparent sur la fiabilit√© des sources

DOCUMENTS (tri√©s par pertinence):
{context}

QUESTION: {question}

R√âPONSE D√âTAILL√âE:""")
        
        messages = prompt.format_messages(context=context, question=query)
        response = self.llm.invoke(messages)
        
        return response.content


class SelfReflectiveRAG(RAGStrategy):
    """
    Strat√©gie RAG auto-r√©flexive qui √©value et raffine ses propres r√©ponses.
    
    Processus :
    1. G√©n√©ration initiale de la r√©ponse
    2. Auto-√©valuation de la r√©ponse
    3. Raffinement si n√©cessaire
    4. R√©p√©tition jusqu'√† satisfaction ou limite atteinte
    """
    
    def __init__(self, llm=None, embeddings=None, vector_store=None,
                 max_iterations: int = 3, quality_threshold: float = 0.8):
        """
        Initialise la strat√©gie auto-r√©flexive.
        
        Args:
            max_iterations: Nombre maximum d'it√©rations de raffinement
            quality_threshold: Seuil de qualit√© pour arr√™ter le raffinement
        """
        super().__init__(llm, embeddings, vector_store)
        self.max_iterations = max_iterations
        self.quality_threshold = quality_threshold
    
    def retrieve(self, query: str, k: int = 5) -> List[Document]:
        """R√©cup√©ration vectorielle standard."""
        if not self.vector_store:
            raise ValueError("Vector store not configured")
        
        return self.vector_store.similarity_search(query, k=k)
    
    def evaluate_response(self, query: str, response: str, documents: List[Document]) -> Dict[str, float]:
        """
        Auto-√©value la qualit√© de la r√©ponse g√©n√©r√©e.
        
        Args:
            query: Requ√™te originale
            response: R√©ponse g√©n√©r√©e
            documents: Documents utilis√©s
            
        Returns:
            Dict avec scores de qualit√©
        """
        if not self.llm:
            raise ValueError("LLM not configured")
        
        # Template d'auto-√©valuation
        evaluation_prompt = ChatPromptTemplate.from_template("""
Vous √™tes un √©valuateur expert. Analysez la r√©ponse suivante et donnez des scores de 0 √† 10.

QUESTION ORIGINALE: {question}

R√âPONSE √Ä √âVALUER: {response}

CONTEXTE DISPONIBLE: {context}

√âvaluez selon ces crit√®res (r√©pondez UNIQUEMENT par les scores num√©riques):
1. PERTINENCE (0-10): La r√©ponse r√©pond-elle √† la question?
2. PR√âCISION (0-10): Les informations sont-elles exactes?
3. COMPL√âTUDE (0-10): La r√©ponse est-elle compl√®te?
4. COH√âRENCE (0-10): La r√©ponse est-elle logique et bien structur√©e?
5. UTILISATION_SOURCES (0-10): Les sources sont-elles bien utilis√©es?

Format de r√©ponse:
PERTINENCE: X
PR√âCISION: X
COMPL√âTUDE: X
COH√âRENCE: X
UTILISATION_SOURCES: X""")
        
        # Pr√©paration du contexte
        context = "\n".join([doc.page_content[:200] + "..." for doc in documents])
        
        # √âvaluation
        messages = evaluation_prompt.format_messages(
            question=query,
            response=response,
            context=context
        )
        
        evaluation_response = self.llm.invoke(messages)
        
        # Parsing des scores
        scores = {}
        try:
            for line in evaluation_response.content.split('\n'):
                if ':' in line:
                    criterion, score_str = line.split(':', 1)
                    score = float(score_str.strip())
                    scores[criterion.strip()] = score / 10.0  # Normalisation 0-1
        except:
            # Fallback si parsing √©choue
            scores = {
                'PERTINENCE': 0.7,
                'PR√âCISION': 0.7,
                'COMPL√âTUDE': 0.7,
                'COH√âRENCE': 0.7,
                'UTILISATION_SOURCES': 0.7
            }
        
        return scores
    
    def refine_response(self, query: str, initial_response: str, 
                       documents: List[Document], evaluation_scores: Dict[str, float]) -> str:
        """
        Raffine la r√©ponse bas√©e sur l'√©valuation.
        
        Args:
            query: Requ√™te originale
            initial_response: R√©ponse initiale
            documents: Documents utilis√©s
            evaluation_scores: Scores d'√©valuation
            
        Returns:
            R√©ponse raffin√©e
        """
        if not self.llm:
            raise ValueError("LLM not configured")
        
        # Identification des points faibles
        weak_points = [k for k, v in evaluation_scores.items() if v < 0.6]
        
        if not weak_points:
            return initial_response
        
        # Template de raffinement
        refinement_prompt = ChatPromptTemplate.from_template("""
Vous devez am√©liorer la r√©ponse suivante en vous concentrant sur les aspects faibles identifi√©s.

QUESTION ORIGINALE: {question}

R√âPONSE INITIALE: {initial_response}

CONTEXTE DISPONIBLE: {context}

ASPECTS √Ä AM√âLIORER: {weak_points}

INSTRUCTIONS:
- Gardez les bonnes parties de la r√©ponse initiale
- Concentrez-vous sur l'am√©lioration des aspects faibles
- Utilisez mieux le contexte disponible
- Soyez plus pr√©cis et complet

R√âPONSE AM√âLIOR√âE:""")
        
        # Pr√©paration du contexte
        context = "\n\n".join([doc.page_content for doc in documents])
        weak_points_str = ", ".join(weak_points)
        
        # Raffinement
        messages = refinement_prompt.format_messages(
            question=query,
            initial_response=initial_response,
            context=context,
            weak_points=weak_points_str
        )
        
        refined_response = self.llm.invoke(messages)
        
        return refined_response.content
    
    def generate(self, query: str, documents: List[Document]) -> str:
        """
        G√©n√©ration avec auto-√©valuation et raffinement it√©ratif.
        
        Args:
            query: Requ√™te utilisateur
            documents: Documents de contexte
            
        Returns:
            R√©ponse raffin√©e
        """
        if not self.llm:
            raise ValueError("LLM not configured")
        
        # G√©n√©ration initiale
        initial_response = self._generate_initial_response(query, documents)
        current_response = initial_response
        
        print(f"ü§î G√©n√©ration initiale termin√©e")
        
        # Boucle de raffinement
        for iteration in range(self.max_iterations):
            print(f"üîÑ It√©ration de raffinement {iteration + 1}/{self.max_iterations}")
            
            # Auto-√©valuation
            scores = self.evaluate_response(query, current_response, documents)
            
            # Calcul du score global
            overall_score = sum(scores.values()) / len(scores)
            print(f"üìä Score global: {overall_score:.2f}")
            
            # Arr√™t si qualit√© suffisante
            if overall_score >= self.quality_threshold:
                print(f"‚úÖ Qualit√© suffisante atteinte (seuil: {self.quality_threshold})")
                break
            
            # Raffinement
            current_response = self.refine_response(query, current_response, documents, scores)
            print(f"üîß R√©ponse raffin√©e")
        
        return current_response
    
    def _generate_initial_response(self, query: str, documents: List[Document]) -> str:
        """G√©n√®re la r√©ponse initiale."""
        context = "\n\n".join([doc.page_content for doc in documents])
        
        prompt = ChatPromptTemplate.from_template("""
Vous √™tes un assistant IA expert. R√©pondez √† la question de mani√®re d√©taill√©e et pr√©cise.

CONTEXTE:
{context}

QUESTION: {question}

R√âPONSE:""")
        
        messages = prompt.format_messages(context=context, question=query)
        response = self.llm.invoke(messages)
        
        return response.content


# Factory pour cr√©er les strat√©gies
class RAGStrategyFactory:
    """Factory pour cr√©er les diff√©rentes strat√©gies RAG."""
    
    @staticmethod
    def create_strategy(strategy_type: str, **kwargs) -> RAGStrategy:
        """
        Cr√©e une strat√©gie RAG selon le type sp√©cifi√©.
        
        Args:
            strategy_type: Type de strat√©gie ('naive', 'hybrid', 'corrective', 'reflective')
            **kwargs: Arguments pour la strat√©gie
            
        Returns:
            Instance de la strat√©gie RAG
        """
        strategies = {
            'naive': NaiveRAG,
            'hybrid': HybridSearchRAG,
            'corrective': CorrectiveRAG,
            'reflective': SelfReflectiveRAG
        }
        
        if strategy_type not in strategies:
            raise ValueError(f"Strat√©gie inconnue: {strategy_type}. Disponibles: {list(strategies.keys())}")
        
        return strategies[strategy_type](**kwargs)
    
    @staticmethod
    def list_strategies() -> List[str]:
        """Retourne la liste des strat√©gies disponibles."""
        return ['naive', 'hybrid', 'corrective', 'reflective']